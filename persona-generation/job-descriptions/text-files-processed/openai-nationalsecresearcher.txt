# Job Overview

- Role: National Security Threat Researcher
- Team: Preparedness
- Reports to: CTO
- Location: San Francisco, CA

# Team Mission

- Monitor and predict capabilities of frontier AI systems
- Identify potential misuse risks with catastrophic societal impact
- Develop procedures, infrastructure, and partnerships to mitigate risks
- Ensure safety infrastructure for highly capable AI systems, including AGI

# Responsibilities

- Use domain expertise to understand national security-related AI safety risks
- Design and refine evaluations of frontier AI models to assess risks
- Contribute to risk management and best practices for AI safety evaluations

# Required Qualifications

- Experience in national security threat prevention, preferably cybersecurity
- Interest in understanding AI safety underpinnings
- Familiarity with software engineering
- Ability to think outside the box and robust "red-teaming mindset"
- Ability to operate effectively in a dynamic, fast-paced research environment
- Ability to scope and deliver projects end-to-end

# Preferred Qualifications

- Experience in ML research engineering, ML observability, large language model applications
- Understanding of societal aspects of AI deployment
- Ability to work cross-functionally
- Excellent communication skills

# About OpenAI

- AI research and deployment company
- Dedicated to ensuring AI benefits all of humanity
- Pushes boundaries of AI capabilities while prioritizing safety
- Values diversity, equity, and inclusion